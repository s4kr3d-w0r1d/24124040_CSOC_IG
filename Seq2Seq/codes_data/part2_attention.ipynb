{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwcH1phzAr0_"
   },
   "source": [
    "## Part 2: Seq2Seq with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gd_uGVLDAyy5"
   },
   "source": [
    "1. Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-19T09:14:05.069Z",
     "iopub.execute_input": "2025-06-19T09:13:51.019818Z",
     "iopub.status.busy": "2025-06-19T09:13:51.019532Z"
    },
    "id": "14avqKrvGNmp",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 09:13:53.805390: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750324434.178719      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750324434.286729      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-19T09:17:53.214576Z",
     "iopub.status.busy": "2025-06-19T09:17:53.213967Z",
     "iopub.status.idle": "2025-06-19T09:17:53.218989Z",
     "shell.execute_reply": "2025-06-19T09:17:53.218429Z",
     "shell.execute_reply.started": "2025-06-19T09:17:53.214551Z"
    },
    "id": "lzGiyn4RpDXP",
    "outputId": "fa22e08a-2d77-4168-fd2e-b9968b537e85",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, AdditiveAttention, TimeDistributed, Concatenate, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Jcyze8wE-Vc"
   },
   "source": [
    "2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T09:16:25.061564Z",
     "iopub.status.busy": "2025-06-19T09:16:25.061271Z",
     "iopub.status.idle": "2025-06-19T09:16:25.069008Z",
     "shell.execute_reply": "2025-06-19T09:16:25.068436Z",
     "shell.execute_reply.started": "2025-06-19T09:16:25.061543Z"
    },
    "id": "PE6CNLMTFEXL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "eng_vocab_size = config['eng_vocab_size']\n",
    "fra_vocab_size = config['fra_vocab_size']\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_UNITS = 256\n",
    "STACKED_LAYERS = 2\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GLxe837BaOL"
   },
   "source": [
    "3. Load Preprocessed Data & Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-19T09:16:33.287845Z",
     "iopub.status.busy": "2025-06-19T09:16:33.287254Z",
     "iopub.status.idle": "2025-06-19T09:16:33.844427Z",
     "shell.execute_reply": "2025-06-19T09:16:33.843529Z",
     "shell.execute_reply.started": "2025-06-19T09:16:33.287821Z"
    },
    "id": "TB-rd8pGqAWO",
    "outputId": "f8057348-0996-42a0-8484-0eba153f3f88",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = np.load('data.npz', allow_pickle=True)\n",
    "encoder_input_data = np.array(data['encoder_input_data'], dtype=np.int32)\n",
    "decoder_input_data = np.array(data['decoder_input_data'], dtype=np.int32)\n",
    "decoder_target_data = np.array(data['decoder_target_data'], dtype=np.int32)\n",
    "\n",
    "if decoder_target_data.ndim == 3 and decoder_target_data.shape[-1] == 1:\n",
    "    decoder_target_data = np.squeeze(decoder_target_data, axis=-1)\n",
    "\n",
    "with open('en_embedding_matrix.pkl', 'rb') as f:\n",
    "    en_embedding_matrix = pickle.load(f)\n",
    "\n",
    "val_size = int(0.1 * len(encoder_input_data))\n",
    "\n",
    "def create_bucketed_dataset(enc, dec, tgt, batch_size):\n",
    "    def gen():\n",
    "        for x, y, z in zip(enc, dec, tgt):\n",
    "            yield {\"encoder_input\": x, \"decoder_input\": y, \"decoder_target\": z}\n",
    "\n",
    "    output_signature = {\n",
    "        \"encoder_input\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        \"decoder_input\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        \"decoder_target\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "    }\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(gen, output_signature=output_signature)\n",
    "\n",
    "    def map_fn(sample):\n",
    "        return (sample[\"encoder_input\"], sample[\"decoder_input\"]), sample[\"decoder_target\"]\n",
    "\n",
    "    def bucket_by_seq_len(example):\n",
    "        enc_len = tf.shape(example[\"encoder_input\"])[0]\n",
    "        return tf.cast(enc_len // 10, tf.int64)  # bucket keys\n",
    "\n",
    "    dataset = dataset.apply(\n",
    "        tf.data.experimental.group_by_window(\n",
    "            key_func=bucket_by_seq_len,\n",
    "            reduce_func=lambda key, ds: ds.map(map_fn).padded_batch(\n",
    "                batch_size,\n",
    "                padded_shapes=(([None], [None]), [None]),\n",
    "                padding_values=((0, 0), 0),\n",
    "                drop_remainder=True\n",
    "            ),\n",
    "            window_size=batch_size\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "train_dataset = create_bucketed_dataset(\n",
    "    encoder_input_data[:-val_size],\n",
    "    decoder_input_data[:-val_size],\n",
    "    decoder_target_data[:-val_size],\n",
    "    batch_size=48\n",
    ")\n",
    "\n",
    "val_dataset = create_bucketed_dataset(\n",
    "    encoder_input_data[-val_size:],\n",
    "    decoder_input_data[-val_size:],\n",
    "    decoder_target_data[-val_size:],\n",
    "    batch_size=48\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB7kcZD5qhih"
   },
   "source": [
    "4. Build Seq2Seq Model with Additive Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "execution": {
     "iopub.execute_input": "2025-06-19T09:18:28.840591Z",
     "iopub.status.busy": "2025-06-19T09:18:28.839833Z",
     "iopub.status.idle": "2025-06-19T09:18:29.130081Z",
     "shell.execute_reply": "2025-06-19T09:18:29.129571Z",
     "shell.execute_reply.started": "2025-06-19T09:18:28.840564Z"
    },
    "id": "MlGsMfd_B-qb",
    "outputId": "4d624a5d-e43d-4746-fd0c-ad91b7c3dc92",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ encoder_embedding         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,914,200</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)               │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ decoder_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_2           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">731,136</span> │ encoder_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │                        │\n",
       "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │                │                        │\n",
       "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]           │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ decoder_embedding         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,088,700</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)               │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,255,424</span> │ decoder_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]                  │                │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ attention_layer           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>)       │                        │                │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ attention_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ output_dense              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50887</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">52,159,175</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │                        │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ encoder_embedding         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │      \u001b[38;5;34m2,914,200\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)               │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ decoder_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_2           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),    │        \u001b[38;5;34m731,136\u001b[0m │ encoder_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │                        │\n",
       "│                           │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │                │                        │\n",
       "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]           │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ decoder_embedding         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │      \u001b[38;5;34m5,088,700\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)               │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m3\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m4\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),    │      \u001b[38;5;34m1,255,424\u001b[0m │ decoder_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ concatenate_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                           │ \u001b[38;5;34m512\u001b[0m)]                  │                │ concatenate_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ attention_layer           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m)       │                        │                │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ attention_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ output_dense              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50887\u001b[0m)    │     \u001b[38;5;34m52,159,175\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │                        │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,149,147</span> (237.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62,149,147\u001b[0m (237.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,149,147</span> (237.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,149,147\u001b[0m (237.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None,), name=\"encoder_input\")\n",
    "encoder_embedding = Embedding(\n",
    "    input_dim=eng_vocab_size,\n",
    "    output_dim=EMBEDDING_DIM,\n",
    "    weights=[en_embedding_matrix],\n",
    "    trainable=True,\n",
    "    name=\"encoder_embedding\"\n",
    ")(encoder_inputs)\n",
    "\n",
    "encoder_lstm1 = Bidirectional(LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True))\n",
    "encoder_output1, fh1, fc1, bh1, bc1 = encoder_lstm1(encoder_embedding)\n",
    "\n",
    "encoder_states_h = Concatenate()([fh1, bh1])\n",
    "encoder_states_c = Concatenate()([fc1, bc1])\n",
    "encoder_states = [encoder_states_h, encoder_states_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None,), name=\"decoder_input\")\n",
    "decoder_embedding = Embedding(fra_vocab_size, EMBEDDING_DIM, trainable=True, name=\"decoder_embedding\")(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(HIDDEN_UNITS * 2, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "attention = AdditiveAttention(name=\"attention_layer\")\n",
    "context_vector = attention([decoder_outputs, encoder_output1])\n",
    "\n",
    "decoder_combined_context = Concatenate(axis=-1)([decoder_outputs, context_vector])\n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(fra_vocab_size, activation=\"softmax\", dtype=\"float32\"), name=\"output_dense\")\n",
    "decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "\n",
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
    "\n",
    "def masked_sparse_accuracy(y_true, y_pred):\n",
    "    y_pred_labels = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    correct = tf.cast(tf.equal(y_true, y_pred_labels), tf.float32) * mask\n",
    "    return tf.reduce_sum(correct) / tf.reduce_sum(mask)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[masked_sparse_accuracy]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LU7ckjLVCxeE"
   },
   "source": [
    "5. Training with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-19T09:19:07.601072Z",
     "iopub.status.busy": "2025-06-19T09:19:07.600262Z",
     "iopub.status.idle": "2025-06-19T12:00:27.678641Z",
     "shell.execute_reply": "2025-06-19T12:00:27.677976Z",
     "shell.execute_reply.started": "2025-06-19T09:19:07.601046Z"
    },
    "id": "IBeur57OwTgS",
    "outputId": "410fe6be-d918-41b2-f05b-8e796993e4b0",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750324754.883149     113 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - loss: 1.3788 - masked_sparse_accuracy: 0.1405\n",
      "Epoch 1: val_loss improved from inf to 0.67216, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 518ms/step - loss: 1.3781 - masked_sparse_accuracy: 0.1405 - val_loss: 0.6722 - val_masked_sparse_accuracy: 0.2863\n",
      "Epoch 2/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - loss: 0.6256 - masked_sparse_accuracy: 0.3196\n",
      "Epoch 2: val_loss improved from 0.67216 to 0.53328, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 524ms/step - loss: 0.6256 - masked_sparse_accuracy: 0.3197 - val_loss: 0.5333 - val_masked_sparse_accuracy: 0.3970\n",
      "Epoch 3/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - loss: 0.5090 - masked_sparse_accuracy: 0.4119\n",
      "Epoch 3: val_loss improved from 0.53328 to 0.45133, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 524ms/step - loss: 0.5089 - masked_sparse_accuracy: 0.4120 - val_loss: 0.4513 - val_masked_sparse_accuracy: 0.4586\n",
      "Epoch 4/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - loss: 0.4312 - masked_sparse_accuracy: 0.4775\n",
      "Epoch 4: val_loss improved from 0.45133 to 0.39659, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 525ms/step - loss: 0.4311 - masked_sparse_accuracy: 0.4775 - val_loss: 0.3966 - val_masked_sparse_accuracy: 0.5095\n",
      "Epoch 5/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - loss: 0.3827 - masked_sparse_accuracy: 0.5222\n",
      "Epoch 5: val_loss improved from 0.39659 to 0.35804, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 526ms/step - loss: 0.3827 - masked_sparse_accuracy: 0.5222 - val_loss: 0.3580 - val_masked_sparse_accuracy: 0.5461\n",
      "Epoch 6/30\n",
      "\u001b[1m235/703\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:53\u001b[0m 500ms/step - loss: 0.3510 - masked_sparse_accuracy: 0.5495"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: val_loss improved from 0.35804 to 0.34820, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 194ms/step - loss: 0.3497 - masked_sparse_accuracy: 0.5509 - val_loss: 0.3482 - val_masked_sparse_accuracy: 0.5559\n",
      "Epoch 7/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - loss: 0.3335 - masked_sparse_accuracy: 0.5630\n",
      "Epoch 7: val_loss improved from 0.34820 to 0.32760, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 527ms/step - loss: 0.3335 - masked_sparse_accuracy: 0.5630 - val_loss: 0.3276 - val_masked_sparse_accuracy: 0.5767\n",
      "Epoch 8/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - loss: 0.2973 - masked_sparse_accuracy: 0.5936\n",
      "Epoch 8: val_loss improved from 0.32760 to 0.30899, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 527ms/step - loss: 0.2973 - masked_sparse_accuracy: 0.5937 - val_loss: 0.3090 - val_masked_sparse_accuracy: 0.5923\n",
      "Epoch 9/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - loss: 0.2664 - masked_sparse_accuracy: 0.6165\n",
      "Epoch 9: val_loss improved from 0.30899 to 0.29638, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 527ms/step - loss: 0.2664 - masked_sparse_accuracy: 0.6165 - val_loss: 0.2964 - val_masked_sparse_accuracy: 0.6051\n",
      "Epoch 10/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - loss: 0.2391 - masked_sparse_accuracy: 0.6398\n",
      "Epoch 10: val_loss improved from 0.29638 to 0.28484, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 528ms/step - loss: 0.2391 - masked_sparse_accuracy: 0.6398 - val_loss: 0.2848 - val_masked_sparse_accuracy: 0.6195\n",
      "Epoch 11/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - loss: 0.2220 - masked_sparse_accuracy: 0.6567\n",
      "Epoch 11: val_loss improved from 0.28484 to 0.27555, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 528ms/step - loss: 0.2220 - masked_sparse_accuracy: 0.6567 - val_loss: 0.2756 - val_masked_sparse_accuracy: 0.6297\n",
      "Epoch 12/30\n",
      "\u001b[1m235/703\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:54\u001b[0m 501ms/step - loss: 0.2107 - masked_sparse_accuracy: 0.6679\n",
      "Epoch 12: val_loss improved from 0.27555 to 0.27334, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 194ms/step - loss: 0.2097 - masked_sparse_accuracy: 0.6674 - val_loss: 0.2733 - val_masked_sparse_accuracy: 0.6327\n",
      "Epoch 13/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502ms/step - loss: 0.2004 - masked_sparse_accuracy: 0.6755\n",
      "Epoch 13: val_loss improved from 0.27334 to 0.27138, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 529ms/step - loss: 0.2003 - masked_sparse_accuracy: 0.6755 - val_loss: 0.2714 - val_masked_sparse_accuracy: 0.6353\n",
      "Epoch 14/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - loss: 0.1845 - masked_sparse_accuracy: 0.6922\n",
      "Epoch 14: val_loss improved from 0.27138 to 0.26791, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 529ms/step - loss: 0.1845 - masked_sparse_accuracy: 0.6922 - val_loss: 0.2679 - val_masked_sparse_accuracy: 0.6379\n",
      "Epoch 15/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - loss: 0.1696 - masked_sparse_accuracy: 0.7088\n",
      "Epoch 15: val_loss improved from 0.26791 to 0.26547, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 528ms/step - loss: 0.1696 - masked_sparse_accuracy: 0.7088 - val_loss: 0.2655 - val_masked_sparse_accuracy: 0.6401\n",
      "Epoch 16/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - loss: 0.1564 - masked_sparse_accuracy: 0.7273\n",
      "Epoch 16: val_loss improved from 0.26547 to 0.26171, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 527ms/step - loss: 0.1564 - masked_sparse_accuracy: 0.7273 - val_loss: 0.2617 - val_masked_sparse_accuracy: 0.6494\n",
      "Epoch 17/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - loss: 0.1476 - masked_sparse_accuracy: 0.7407\n",
      "Epoch 17: val_loss improved from 0.26171 to 0.25913, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 527ms/step - loss: 0.1476 - masked_sparse_accuracy: 0.7407 - val_loss: 0.2591 - val_masked_sparse_accuracy: 0.6562\n",
      "Epoch 18/30\n",
      "\u001b[1m235/703\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:52\u001b[0m 498ms/step - loss: 0.1423 - masked_sparse_accuracy: 0.7484\n",
      "Epoch 18: val_loss improved from 0.25913 to 0.25834, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 194ms/step - loss: 0.1414 - masked_sparse_accuracy: 0.7492 - val_loss: 0.2583 - val_masked_sparse_accuracy: 0.6575\n",
      "Epoch 19/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - loss: 0.1341 - masked_sparse_accuracy: 0.7568\n",
      "Epoch 19: val_loss did not improve from 0.25834\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 516ms/step - loss: 0.1341 - masked_sparse_accuracy: 0.7568 - val_loss: 0.2589 - val_masked_sparse_accuracy: 0.6577\n",
      "Epoch 20/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - loss: 0.1268 - masked_sparse_accuracy: 0.7687\n",
      "Epoch 20: val_loss did not improve from 0.25834\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 515ms/step - loss: 0.1268 - masked_sparse_accuracy: 0.7687 - val_loss: 0.2595 - val_masked_sparse_accuracy: 0.6593\n",
      "Epoch 21/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - loss: 0.1207 - masked_sparse_accuracy: 0.7810\n",
      "Epoch 21: val_loss improved from 0.25834 to 0.25767, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 517ms/step - loss: 0.1207 - masked_sparse_accuracy: 0.7810 - val_loss: 0.2577 - val_masked_sparse_accuracy: 0.6580\n",
      "Epoch 22/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - loss: 0.1150 - masked_sparse_accuracy: 0.7904\n",
      "Epoch 22: val_loss improved from 0.25767 to 0.25753, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 511ms/step - loss: 0.1150 - masked_sparse_accuracy: 0.7904 - val_loss: 0.2575 - val_masked_sparse_accuracy: 0.6653\n",
      "Epoch 23/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - loss: 0.1105 - masked_sparse_accuracy: 0.7985\n",
      "Epoch 23: val_loss did not improve from 0.25753\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 506ms/step - loss: 0.1105 - masked_sparse_accuracy: 0.7985 - val_loss: 0.2586 - val_masked_sparse_accuracy: 0.6648\n",
      "Epoch 24/30\n",
      "\u001b[1m235/703\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:45\u001b[0m 483ms/step - loss: 0.1087 - masked_sparse_accuracy: 0.8018\n",
      "Epoch 24: val_loss improved from 0.25753 to 0.25698, saving model to best_model_part2_attention.h5\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 188ms/step - loss: 0.1079 - masked_sparse_accuracy: 0.8017 - val_loss: 0.2570 - val_masked_sparse_accuracy: 0.6706\n",
      "Epoch 25/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - loss: 0.1018 - masked_sparse_accuracy: 0.8088\n",
      "Epoch 25: val_loss did not improve from 0.25698\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 505ms/step - loss: 0.1018 - masked_sparse_accuracy: 0.8088 - val_loss: 0.2593 - val_masked_sparse_accuracy: 0.6672\n",
      "Epoch 26/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - loss: 0.0981 - masked_sparse_accuracy: 0.8162\n",
      "Epoch 26: val_loss did not improve from 0.25698\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 506ms/step - loss: 0.0981 - masked_sparse_accuracy: 0.8162 - val_loss: 0.2604 - val_masked_sparse_accuracy: 0.6679\n",
      "Epoch 27/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - loss: 0.0957 - masked_sparse_accuracy: 0.8221\n",
      "Epoch 27: val_loss did not improve from 0.25698\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 505ms/step - loss: 0.0957 - masked_sparse_accuracy: 0.8221 - val_loss: 0.2610 - val_masked_sparse_accuracy: 0.6648\n",
      "Epoch 28/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - loss: 0.0923 - masked_sparse_accuracy: 0.8292\n",
      "Epoch 28: val_loss did not improve from 0.25698\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 503ms/step - loss: 0.0923 - masked_sparse_accuracy: 0.8292 - val_loss: 0.2589 - val_masked_sparse_accuracy: 0.6716\n",
      "Epoch 29/30\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - loss: 0.0903 - masked_sparse_accuracy: 0.8336\n",
      "Epoch 29: val_loss did not improve from 0.25698\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 503ms/step - loss: 0.0903 - masked_sparse_accuracy: 0.8336 - val_loss: 0.2618 - val_masked_sparse_accuracy: 0.6719\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    \"best_model_part2_attention.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "steps_per_epoch = len(encoder_input_data[:-val_size]) // BATCH_SIZE\n",
    "validation_steps = len(encoder_input_data[-val_size:]) // BATCH_SIZE\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[checkpoint, early_stop],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-19T12:30:10.450779Z",
     "iopub.status.busy": "2025-06-19T12:30:10.450106Z",
     "iopub.status.idle": "2025-06-19T12:33:31.361046Z",
     "shell.execute_reply": "2025-06-19T12:33:31.360316Z",
     "shell.execute_reply.started": "2025-06-19T12:30:10.450756Z"
    },
    "id": "uv2ONx9FzgHL",
    "outputId": "8e1671b7-0082-4a2b-bc08-1a6a0772fd13",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 | Pred: tom est en faveur. | Ref: tom est en faveur.\n",
      "Sample 10 | Pred: il ai a seul. raison de faim. notre fenêtre, | Ref: il ai a seul. raison de faim. connais fenêtre,\n",
      "Sample 20 | Pred: je pense que tu cet demain. pensait chose | Ref: je pense que vous faites demain. pensait chose\n",
      "Sample 30 | Pred: je tenu que vous espion pas plus part | Ref: je tenu que tu grappe. pas plus part\n",
      "Sample 40 | Pred: les veux-tu fit des manger crier | Ref: les veux-tu fit des manger « ça\n",
      "Sample 50 | Pred: je ne depuis vraiment pas que tu le salée. | Ref: mourir. vraiment que vous l'as ce embrassés\n",
      "Sample 60 | Pred: l'accusèrent pu étonnant | Ref: éponge pu tout\n",
      "Sample 70 | Pred: ton français est cabane | Ref: ton français est cabane\n",
      "Sample 80 | Pred: boston. rencontre votre prie. tout | Ref: pins. êtes-vous vous crois\n",
      "Sample 90 | Pred: il ne n'arrive pas de ma l'arbre | Ref: il ne n'arrive pas ma l'arbre\n",
      "BLEU score: 0.3712\n"
     ]
    }
   ],
   "source": [
    "start_token = '<sos>'\n",
    "end_token = '<eos>'\n",
    "\n",
    "with open('fra_tokenizer.pkl', 'rb') as f:\n",
    "    fra_tokenizer = pickle.load(f)\n",
    "\n",
    "def tokens_to_sentence(token_ids, tokenizer, end_token):\n",
    "    words = []\n",
    "    for t in token_ids:\n",
    "        if t == end_token:\n",
    "            break\n",
    "        word = tokenizer.index_word.get(t, '') \n",
    "        if word == '':\n",
    "            continue\n",
    "        words.append(word)\n",
    "    return words\n",
    "\n",
    "def beam_search_decode(\n",
    "    model,\n",
    "    encoder_input_seq,\n",
    "    start_token,\n",
    "    end_token,\n",
    "    fra_vocab_size,\n",
    "    beam_width=3,\n",
    "    max_decoder_seq_length=50,\n",
    "):\n",
    "    start_seq = [start_token]\n",
    "    beam = [(start_seq, 0.0)]\n",
    "    for _ in range(max_decoder_seq_length):\n",
    "        all_candidates = []\n",
    "        for seq, score in beam:\n",
    "            if seq[-1] == end_token:\n",
    "                all_candidates.append((seq, score))\n",
    "                continue\n",
    "            enc_input = encoder_input_seq\n",
    "            dec_input = np.array(seq)[np.newaxis, :]\n",
    "            preds = model.predict([enc_input, dec_input], verbose=0)\n",
    "            next_token_logits = preds[0, -1, :]\n",
    "            log_probs = np.log(next_token_logits + 1e-9)\n",
    "            top_tokens = np.argsort(log_probs)[-beam_width:]\n",
    "            for t in top_tokens:\n",
    "                candidate_seq = seq + [int(t)]\n",
    "                candidate_score = score + log_probs[t]\n",
    "                all_candidates.append((candidate_seq, candidate_score))\n",
    "        ordered = sorted(all_candidates, key=lambda tup: tup[1], reverse=True)\n",
    "        beam = ordered[:beam_width]\n",
    "        if all(seq[-1] == end_token for seq, _ in beam):\n",
    "            break\n",
    "    best_sequence = beam[0][0]\n",
    "    return best_sequence\n",
    "\n",
    "\n",
    "def calculate_bleu_score(\n",
    "    model,\n",
    "    encoder_input_data,\n",
    "    decoder_target_data,\n",
    "    fra_tokenizer,\n",
    "    start_token_id,\n",
    "    end_token_id,\n",
    "    beam_width=3,\n",
    "    max_decoder_seq_length=50,\n",
    "    num_samples=100,\n",
    "):\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        enc_seq = encoder_input_data[i : i + 1]\n",
    "        target_seq = decoder_target_data[i]\n",
    "        pred_seq = beam_search_decode(\n",
    "            model,\n",
    "            enc_seq,\n",
    "            start_token=start_token_id,\n",
    "            end_token=end_token_id,\n",
    "            fra_vocab_size=len(fra_tokenizer.word_index) + 1,\n",
    "            beam_width=beam_width,\n",
    "            max_decoder_seq_length=max_decoder_seq_length,\n",
    "        )\n",
    "        pred_sentence = tokens_to_sentence(pred_seq[1:], fra_tokenizer, end_token_id)\n",
    "        ref_sentence = tokens_to_sentence(target_seq, fra_tokenizer, end_token_id)\n",
    "        references.append([ref_sentence])\n",
    "        hypotheses.append(pred_sentence)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Sample {i} | Pred: {' '.join(pred_sentence)} | Ref: {' '.join(ref_sentence)}\")\n",
    "    bleu_score = corpus_bleu(references, hypotheses)\n",
    "    return bleu_score\n",
    "\n",
    "bleu = calculate_bleu_score(\n",
    "    model,\n",
    "    encoder_input_data[-100:],\n",
    "    decoder_target_data[-100:],\n",
    "    fra_tokenizer,\n",
    "    start_token_id=fra_tokenizer.word_index.get(start_token),\n",
    "    end_token_id=fra_tokenizer.word_index.get(end_token),\n",
    "    max_decoder_seq_length=50,\n",
    "    num_samples=100\n",
    ")\n",
    "\n",
    "print(f\"BLEU score: {bleu:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7695829,
     "sourceId": 12215826,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
